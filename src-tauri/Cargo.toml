[package]
name = "private-transcript"
version = "1.0.0"
description = "Privacy-first offline transcription and note generation"
authors = ["you"]
license = "MIT"
repository = ""
edition = "2021"
default-run = "private-transcript"

[build-dependencies]
tauri-build = { version = "2.0", features = [] }

[dependencies]
# Tauri
tauri = { version = "2.0", features = ["protocol-asset"] }
tauri-plugin-shell = "2.0"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Async runtime
tokio = { version = "1.35", features = ["full"] }

# Database
sqlx = { version = "0.7", features = ["runtime-tokio", "sqlite"] }

# Whisper transcription: Now using WhisperKit (Swift/CoreML) via subprocess
# whisper-rs removed - caused BLAS crashes on M4 in Tauri/WebKit context

# LLM inference (native bindings)
llama-cpp-2 = "0.1"

# HTTP client (for Ollama/OpenRouter fallback)
reqwest = { version = "0.12", features = ["json", "stream"] }

# Audio processing (replaces ffmpeg)
symphonia = { version = "0.5", features = ["all"] }
rubato = "0.15"

# Model downloading from HuggingFace
hf-hub = { version = "0.3", features = ["tokio"] }

# State management
parking_lot = "0.12"
once_cell = "1.19"

# Utilities
uuid = { version = "1.7", features = ["v4", "serde"] }
chrono = { version = "0.4", features = ["serde"] }
thiserror = "1.0"
anyhow = "1.0"
dirs = "5.0"
rand = "0.8"
futures = "0.3"

# Document export
printpdf = "0.7"
docx-rs = "0.4"
base64 = "0.22.1"

# Note: whisper-worker binary removed - now using WhisperKit Swift subprocess

[features]
default = ["custom-protocol"]
custom-protocol = ["tauri/custom-protocol"]

# Platform-specific features are handled automatically by whisper-rs and llama-cpp-2
# Metal acceleration is automatic on macOS

# Dev profile optimizations - keeps your code fast to compile while pre-optimizing heavy deps
[profile.dev]
opt-level = 0

[profile.dev.package."*"]
opt-level = 2  # Optimize dependencies even in dev for faster runtime
